# Video Extraction Tool

This tool processes videos, extracts scenes, and uploads the processed content to Supabase storage.

## Prerequisites

- Python 3.8 or higher
- Required Python packages (install using `pip install -r requirements.txt`)
- Supabase account with API credentials
- Google AI API key for Multimodal Embeddings
- OpenAI API key for GPT Vision analysis

## Environment Setup

Create a `.env` file in the root directory with the following variables:

```
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_key
GOOGLE_AI_API_KEY=your_google_ai_api_key
OPENAI_API_KEY=your_openai_api_key
```

## Scene Analysis Methods

The tool now supports multiple advanced scene analysis methods:

### ğŸ¯ Google Multimodal + FAISS Method

1. **Google Multimodal Embeddings**: Uses Google's state-of-the-art multimodal embeddings for superior frame representation
2. **FAISS Vector Database**: Efficient similarity search with video-partitioned storage
3. **K-means Clustering**: Automatic scene detection based on visual similarity
4. **Outlier Removal**: Intelligent filtering of anomalous frames
5. **Smart Scene Merging**: Combines short scenes for better coherence

### ğŸ§  GPT Vision Analysis Method (NEW)

1. **OpenAI GPT-4 Vision**: Advanced visual understanding with natural language descriptions
2. **LangChain Integration**: Structured interaction with OpenAI APIs
3. **Frame Sampling**: Intelligent frame extraction and base64 encoding
4. **Scene Description**: Rich contextual analysis including objects, actions, emotions
5. **JSON Structured Output**: Detailed scene metadata with timestamps

#### ğŸ”§ GPT Vision Technical Implementation

- **Frame Extraction**: OpenCV-based frame sampling (configurable rate)
- **Base64 Encoding**: Efficient image encoding for API transmission
- **Token Optimization**: Smart frame sampling to stay within token limits
- **LangChain ChatOpenAI**: Structured model interaction with proper error handling
- **JSON Parsing**: Robust response parsing with multiple format support

#### ğŸ“Š GPT Vision Benefits

- **Rich Descriptions**: Natural language scene understanding
- **Context Awareness**: Understands relationships between objects and actions
- **Emotion Detection**: Identifies emotional states and tone
- **OCR Capabilities**: Extracts visible text from video frames
- **Flexible Prompting**: Custom prompts for specific analysis needs

## Usage

### Simplified Command (Recommended)

Run the tool using the simple wrapper script:

```bash
./extract.py -v PATH_TO_YOUR_VIDEO
```

### Testing Scene Analyzers

#### Test Google Multimodal + FAISS Scene Analyzer

```bash
# Set your Google AI API key
export GOOGLE_AI_API_KEY="your_api_key_here"

# Run the test script
python test_scene_analyzer.py
```

#### Test GPT Vision Scene Analyzer (NEW)

```bash
# Set your OpenAI API key
export OPENAI_API_KEY="your_openai_api_key_here"

# Run the GPT scene analyzer test
python test_gpt_scene_analysis.py

# For batch testing multiple videos
python test_gpt_scene_analysis.py batch
```

### Using GPT Scene Analyzer in Code

```python
from src.server.indexing.gpt_scene_analyzer import analyze_video_with_gpt, analyze_video_with_custom_prompt

# Basic scene analysis with default prompt
result = analyze_video_with_gpt(
    video_path="your_video.mp4",
    chunk_index=0,
    model_name="gpt-4o"
)

# Custom prompt analysis
custom_result = analyze_video_with_custom_prompt(
    video_path="your_video.mp4",
    custom_prompt="Describe this video in detail",
    model_name="gpt-4o"
)
```

### Alternative Methods

Or use the original module path:

```bash
python -m src.client.extract.__index__ --video_path PATH_TO_YOUR_VIDEO
```

With the short form:

```bash
python -m src.client.extract.__index__ -v PATH_TO_YOUR_VIDEO
```

## Processing Steps

The tool performs the following operations:

1. **Video Preprocessing**: Frame extraction at 1 FPS
2. **Scene Analysis** (Choose one method):
   - **Google Multimodal**: Embedding generation + FAISS clustering
   - **GPT Vision**: AI-powered visual understanding + structured description
3. **Vector Storage**: FAISS database with video partitioning (Google method)
4. **Scene Generation**: Temporal grouping and smart merging
5. **Content Upload**: Processed files to Supabase storage

## Output

All processed files, including:

- Preprocessed video (video.mp4)
- Extracted audio (audio.wav)
- Scene information (scenes.json) - **Now with multiple analysis methods**
- Video metadata (metadata.json)
- FAISS vector database (per-project partitioned) - For Google method
- GPT analysis results (JSON format) - For GPT method

are uploaded to a Supabase bucket named after the video ID.

# Attenz AI Project

## ğŸš€ Quick Start - Web Interface

### Gradio Web Interface (NEW) ğŸŒ

The easiest way to interact with the Attenz AI Agent is through the web interface:

```bash
# Install dependencies (includes gradio)
pip install -r requirements.txt

# Set up environment variables
export OPENAI_API_KEY="your_openai_api_key"
export GOOGLE_AI_API_KEY="your_google_ai_api_key"

# Launch the web interface
python run_gradio.py
```

Then open your browser and go to: **http://localhost:7860**

#### ğŸ¯ Features

- **ğŸ’¬ Chat Interface**: Natural conversation with the AI agent
- **ğŸ”§ Tool Integration**: Automatic access to video analysis, search, and more
- **ğŸ“± Responsive Design**: Works on desktop and mobile
- **ğŸ¨ Modern UI**: Clean, intuitive interface with examples
- **ğŸ”„ Session Management**: Clear chat and reset conversations
- **âš¡ Real-time**: Instant responses with progress indicators

#### ğŸ› ï¸ Web Interface Capabilities

- **Video Analysis**: "Analyze the scene in video X"
- **Smart Search**: "Find videos with cars" or "Search for outdoor scenes"
- **Data Insights**: "Show me patterns in my video data"
- **General Assistant**: "What can you help me with?"

## Setup and Testing

### íŒŒì´ì¬ ì›Œí‚¹ ë””ë ‰í† ë¦¬ ì„¤ì •í•˜ê¸°

1. **í„°ë¯¸ë„ì—ì„œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì´ë™í•˜ê¸°**

   ```bash
   cd /path/to/attenz-ai
   ```

2. **í™˜ê²½ ë³€ìˆ˜ ì„¤ì •í•˜ê¸°**

   ```bash
   export GOOGLE_AI_API_KEY="your_google_ai_api_key"
   export OPENAI_API_KEY="your_openai_api_key"
   ```

3. **í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰í•˜ê¸°**
   ```bash
   python test_scene_analyzer.py          # Google Multimodal + FAISS test
   python test_gpt_scene_analysis.py      # GPT Vision scene analysis test
   python test_pipeline.py                # Original pipeline test
   ```

### ìƒˆë¡œìš´ Scene Analyzer í…ŒìŠ¤íŠ¸

#### Google Multimodal + FAISS Method

```bash
# Google AI API í‚¤ ì„¤ì •
export GOOGLE_AI_API_KEY="your_api_key_here"

# ìƒˆë¡œìš´ scene analyzer í…ŒìŠ¤íŠ¸
python test_scene_analyzer.py

# ê²°ê³¼ í™•ì¸
ls test_scenes_google_*.json
ls test_faiss_vector_db/
```

#### GPT Vision Method (NEW)

```bash
# OpenAI API í‚¤ ì„¤ì •
export OPENAI_API_KEY="your_openai_api_key_here"

# GPT scene analyzer í…ŒìŠ¤íŠ¸
python test_gpt_scene_analysis.py

# ê²°ê³¼ í™•ì¸
ls gpt_analysis_result_*.json
ls gpt_custom_analysis_*.txt
```

### ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜ í•´ê²° ë°©ë²•

ë‹¤ìŒ ë°©ë²• ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. **sys.pathë¥¼ í†µí•´ ì„¤ì • (ì½”ë“œì— í¬í•¨ë¨)**

   ```python
   import sys
   import os
   sys.path.append(os.path.dirname(os.path.abspath(__file__)))
   ```

2. **PYTHONPATH í™˜ê²½ë³€ìˆ˜ ì„¤ì •**

   ```bash
   # ë¦¬ëˆ…ìŠ¤/ë§¥
   export PYTHONPATH=/path/to/attenz-ai:$PYTHONPATH

   # ìœˆë„ìš°
   set PYTHONPATH=C:\path\to\attenz-ai;%PYTHONPATH%
   ```

3. **IDE ì„¤ì •ì—ì„œ Source Path ì¶”ê°€**
   - VS Code: settings.jsonì— python.analysis.extraPaths ì„¤ì •
   - PyCharm: í”„ë¡œì íŠ¸ êµ¬ì¡°ì—ì„œ Content Root ì„¤ì •

### í”„ë¡œì íŠ¸ êµ¬ì¡°

```
attenz-ai/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ server/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ indexing/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ pipeline.py
â”‚       â”‚   â”œâ”€â”€ scene_processor.py
â”‚       â”‚   â”œâ”€â”€ scene_analyzer.py          # Google Multimodal + FAISS
â”‚       â”‚   â”œâ”€â”€ gpt_scene_analyzer.py      # ğŸ†• GPT Vision + LangChain
â”‚       â”‚   â”œâ”€â”€ gemini_scene_analyzer.py   # Gemini Vision
â”‚       â”‚   â”œâ”€â”€ google_embeddings.py       # Google Multimodal Embeddings
â”‚       â”‚   â””â”€â”€ vector_db.py               # FAISS Vector Database
â”‚       â””â”€â”€ repository/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ ai_repository.py
â”‚           â””â”€â”€ supabase_repository.py
â”œâ”€â”€ test_scene_analyzer.py                 # Google Multimodal + FAISS test
â”œâ”€â”€ test_gpt_scene_analysis.py             # ğŸ†• GPT Vision scene analysis test
â””â”€â”€ test_pipeline.py
```

## Dependencies

### Dependencies for Advanced Scene Analysis

- `faiss-cpu`: Efficient similarity search and clustering
- `google-generativeai`: Google Multimodal Embeddings API
- `langchain-openai`: LangChain OpenAI integration for GPT Vision
- `langchain-core`: Core LangChain components
- `opencv-python`: Video processing and frame extraction

### Required Python Packages

Install all dependencies:

```bash
pip install -r requirements.txt
```

Key packages include:

- `opencv-python`: Video frame extraction
- `langchain-openai`: GPT Vision integration
- `faiss-cpu`: Vector similarity search
- `google-generativeai`: Google AI services
- `numpy`: Numerical computations
- `supabase`: Database operations
