# Video Extraction Tool

This tool processes videos, extracts scenes, and uploads the processed content to Supabase storage.

## Prerequisites

- Python 3.8 or higher
- Required Python packages (install using `pip install -r requirements.txt`)
- Supabase account with API credentials
- Google AI API key for Multimodal Embeddings

## Environment Setup

Create a `.env` file in the root directory with the following variables:

```
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_key
GOOGLE_AI_API_KEY=your_google_ai_api_key
```

## New Scene Analysis Method

The tool now uses an advanced clustering-based scene analysis method with the following features:

### ğŸ¯ Key Features

1. **Google Multimodal Embeddings**: Uses Google's state-of-the-art multimodal embeddings for superior frame representation
2. **FAISS Vector Database**: Efficient similarity search with video-partitioned storage
3. **K-means Clustering**: Automatic scene detection based on visual similarity
4. **Outlier Removal**: Intelligent filtering of anomalous frames
5. **Smart Scene Merging**: Combines short scenes for better coherence

### ğŸ”§ Technical Implementation

- **Frame Sampling**: Extracts 1 frame per second from video
- **Embedding Generation**: 1408-dimensional Google Multimodal Embeddings
- **Vector Storage**: FAISS IndexFlatIP for cosine similarity search
- **Clustering**: Automatic optimal cluster number detection using silhouette score
- **Scene Generation**: Temporal grouping of similar visual content

### ğŸ“Š Performance Benefits

- **Accuracy**: Superior scene boundary detection compared to traditional methods
- **Scalability**: FAISS enables fast similarity search across large video collections
- **Flexibility**: Video-partitioned storage allows efficient per-video operations
- **Caching**: Intelligent caching system reduces reprocessing time

## Usage

### Simplified Command (Recommended)

Run the tool using the simple wrapper script:

```bash
./extract.py -v PATH_TO_YOUR_VIDEO
```

### Testing the New Scene Analyzer

Test the new Google Multimodal + FAISS scene analyzer:

```bash
# Set your Google AI API key
export GOOGLE_AI_API_KEY="your_api_key_here"

# Run the test script
python test_scene_analyzer.py
```

### Alternative Methods

Or use the original module path:

```bash
python -m src.client.extract.__index__ --video_path PATH_TO_YOUR_VIDEO
```

With the short form:

```bash
python -m src.client.extract.__index__ -v PATH_TO_YOUR_VIDEO
```

## Processing Steps

The tool performs the following operations:

1. **Video Preprocessing**: Frame extraction at 1 FPS
2. **Embedding Generation**: Google Multimodal Embeddings for each frame
3. **Vector Storage**: FAISS database with video partitioning
4. **Clustering Analysis**: K-means clustering with outlier removal
5. **Scene Generation**: Temporal grouping and smart merging
6. **Content Upload**: Processed files to Supabase storage

## Output

All processed files, including:

- Preprocessed video (video.mp4)
- Extracted audio (audio.wav)
- Scene information (scenes.json) - **Now with cluster-based analysis**
- Video metadata (metadata.json)
- FAISS vector database (per-project partitioned)

are uploaded to a Supabase bucket named after the video ID.

# Attenz AI Project

## Setup and Testing

### íŒŒì´ì¬ ì›Œí‚¹ ë””ë ‰í† ë¦¬ ì„¤ì •í•˜ê¸°

1. **í„°ë¯¸ë„ì—ì„œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì´ë™í•˜ê¸°**

   ```bash
   cd /path/to/attenz-ai
   ```

2. **í™˜ê²½ ë³€ìˆ˜ ì„¤ì •í•˜ê¸°**

   ```bash
   export GOOGLE_AI_API_KEY="your_google_ai_api_key"
   ```

3. **í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰í•˜ê¸°**
   ```bash
   python test_scene_analyzer.py  # New Google Multimodal + FAISS test
   python test_pipeline.py        # Original pipeline test
   ```

### ìƒˆë¡œìš´ Scene Analyzer í…ŒìŠ¤íŠ¸

```bash
# Google AI API í‚¤ ì„¤ì •
export GOOGLE_AI_API_KEY="your_api_key_here"

# ìƒˆë¡œìš´ scene analyzer í…ŒìŠ¤íŠ¸
python test_scene_analyzer.py

# ê²°ê³¼ í™•ì¸
ls test_scenes_google_*.json
ls test_faiss_vector_db/
```

### ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜ í•´ê²° ë°©ë²•

ë‹¤ìŒ ë°©ë²• ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. **sys.pathë¥¼ í†µí•´ ì„¤ì • (ì½”ë“œì— í¬í•¨ë¨)**

   ```python
   import sys
   import os
   sys.path.append(os.path.dirname(os.path.abspath(__file__)))
   ```

2. **PYTHONPATH í™˜ê²½ë³€ìˆ˜ ì„¤ì •**

   ```bash
   # ë¦¬ëˆ…ìŠ¤/ë§¥
   export PYTHONPATH=/path/to/attenz-ai:$PYTHONPATH

   # ìœˆë„ìš°
   set PYTHONPATH=C:\path\to\attenz-ai;%PYTHONPATH%
   ```

3. **IDE ì„¤ì •ì—ì„œ Source Path ì¶”ê°€**
   - VS Code: settings.jsonì— python.analysis.extraPaths ì„¤ì •
   - PyCharm: í”„ë¡œì íŠ¸ êµ¬ì¡°ì—ì„œ Content Root ì„¤ì •

### í”„ë¡œì íŠ¸ êµ¬ì¡°

```
attenz-ai/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ server/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ indexing/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ pipeline.py
â”‚       â”‚   â”œâ”€â”€ scene_processor.py
â”‚       â”‚   â”œâ”€â”€ scene_analyzer.py          # ğŸ†• New Google Multimodal + FAISS
â”‚       â”‚   â”œâ”€â”€ google_embeddings.py       # ğŸ†• Google Multimodal Embeddings
â”‚       â”‚   â””â”€â”€ vector_db.py               # ğŸ†• FAISS Vector Database
â”‚       â””â”€â”€ repository/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ ai_repository.py
â”‚           â””â”€â”€ supabase_repository.py
â”œâ”€â”€ test_scene_analyzer.py                 # ğŸ†• New scene analyzer test
â””â”€â”€ test_pipeline.py
```

## Dependencies

### New Dependencies for Advanced Scene Analysis

- `faiss-cpu`: Efficient similarity search and clustering
- `google-generativeai`: Google Multimodal Embeddings API
- `google-cloud-aiplatform`: Alternative Vertex AI support
- `scikit-learn`: Machine learning utilities for clustering

### Installation

```bash
pip install -r requirements.txt
```

## API Keys and Configuration

### Google AI API Key

1. Visit [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Create a new API key
3. Set the environment variable:
   ```bash
   export GOOGLE_AI_API_KEY="your_api_key_here"
   ```

### Supabase Configuration

1. Create a Supabase project
2. Get your project URL and API key
3. Set the environment variables:
   ```bash
   export SUPABASE_URL="your_supabase_url"
   export SUPABASE_KEY="your_supabase_key"
   ```
