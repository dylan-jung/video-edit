import argparse
import json
import os
import sys
from typing import Dict, List, Optional

import numpy as np

# run test_speech_vector_search.py projects/test/ea48283a31baa560/speech_vector_db.faiss -i

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.server.ai_adapter.speech_vector_db import SpeechVectorDB
from src.server.indexing.embedding.openai_embeddings import \
    OpenAIEmbeddingGenerator


def generate_random_query_embedding(dimension: int = 768) -> np.ndarray:
    """
    í…ŒìŠ¤íŠ¸ìš© ëœë¤ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    
    Args:
        dimension: ì„ë² ë”© ì°¨ì› (ê¸°ë³¸ê°’: 768, êµ¬ê¸€ ì„ë² ë”© ì°¨ì›)
        
    Returns:
        ëœë¤ ì„ë² ë”© ë²¡í„°
    """
    return np.random.randn(dimension).astype('float32')


def generate_text_embedding_with_openai(text: str, dimension: int = 768) -> np.ndarray:
    """
    OpenAIë¥¼ ì‚¬ìš©í•œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (ì°¨ì› ì¶•ì†Œ)
    
    Args:
        text: ì…ë ¥ í…ìŠ¤íŠ¸
        dimension: ëª©í‘œ ì°¨ì› (ê¸°ë³¸ê°’: 768)
        
    Returns:
        ì¶•ì†Œëœ ì°¨ì›ì˜ ì„ë² ë”© ë²¡í„°
    """
    try:
        embedding_generator = OpenAIEmbeddingGenerator()
        embedding = embedding_generator.generate_text_embedding(text)
        
        # OpenAI ì„ë² ë”©(3072)ì„ ëª©í‘œ ì°¨ì›(768)ìœ¼ë¡œ ì¶•ì†Œ
        if embedding.shape[0] > dimension:
            # ë‹¨ìˆœ ìŠ¬ë¼ì´ì‹±ìœ¼ë¡œ ì°¨ì› ì¶•ì†Œ
            embedding = embedding[:dimension]
        elif embedding.shape[0] < dimension:
            # íŒ¨ë”©ìœ¼ë¡œ ì°¨ì› í™•ì¥
            padding = np.zeros(dimension - embedding.shape[0])
            embedding = np.concatenate([embedding, padding])
            
        return embedding.astype('float32')
    except Exception as e:
        print(f"âš ï¸  OpenAI ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        print("   ëœë¤ ë²¡í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤...")
        return generate_random_query_embedding(dimension)


def generate_text_embedding_fallback(text: str, dimension: int = 768) -> np.ndarray:
    """
    í…ìŠ¤íŠ¸ ê¸°ë°˜ ì„ë² ë”© ìƒì„± (OpenAI ì‚¬ìš© ë¶ˆê°€ì‹œ í´ë°±)
    í•´ì‹œ ê¸°ë°˜ ë²¡í„° ìƒì„±
    
    Args:
        text: ì…ë ¥ í…ìŠ¤íŠ¸
        dimension: ì„ë² ë”© ì°¨ì›
        
    Returns:
        í…ìŠ¤íŠ¸ ê¸°ë°˜ ì„ë² ë”© ë²¡í„°
    """
    # ê°„ë‹¨í•œ í•´ì‹œ ê¸°ë°˜ ë²¡í„° ìƒì„± (í´ë°±ìš©)
    np.random.seed(hash(text) % (2**32))
    embedding = np.random.randn(dimension).astype('float32')
    np.random.seed()  # ì‹œë“œ ë¦¬ì…‹
    return embedding


def print_search_results(results: List[Dict], query_text: str = None):
    """
    ìŒì„± ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
    
    Args:
        results: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        query_text: ì¿¼ë¦¬ í…ìŠ¤íŠ¸ (ìˆëŠ” ê²½ìš°)
    """
    if query_text:
        print(f"\nğŸ” Query: '{query_text}'")
    print(f"\nğŸ“Š Found {len(results)} similar speech chunks:")
    print("=" * 80)
    
    for i, result in enumerate(results, 1):
        print(f"\nğŸ™ï¸  Rank {i} - Video: {result['video_id']}")
        print(f"   â±ï¸  Time: {result.get('start_time', 'N/A')} - {result.get('end_time', 'N/A')}")
        
        if result.get('similarity_score') is not None:
            print(f"   ğŸ“ Similarity Score: {result['similarity_score']:.4f}")
        if result.get('keyword_score') is not None:
            print(f"   ğŸ”‘ Keyword Score: {result['keyword_score']}")
        
        if result.get('summary'):
            print(f"   ğŸ“ Summary: {result['summary']}")
        
        if result.get('keywords'):
            print(f"   ğŸ·ï¸  Keywords: {', '.join(result['keywords'])}")
        
        if result.get('topics'):
            print(f"   ğŸ† Topics: {', '.join(result['topics'])}")
        
        if result.get('sentiment'):
            print(f"   ğŸ˜Š Sentiment: {result['sentiment']}")
        
        if result.get('importance'):
            print(f"   â­ Importance: {result['importance']}")
        
        if result.get('context'):
            print(f"   ğŸ“– Context: {result['context']}")
        
        if result.get('text'):
            # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì¼ë¶€ë§Œ í‘œì‹œ
            text_preview = ', '.join(result['text'][:3])
            if len(result['text']) > 3:
                text_preview += f" ... (+{len(result['text'])-3} more)"
            print(f"   ğŸ’¬ Text: {text_preview}")
        
        print("-" * 40)


def interactive_search(speech_db: SpeechVectorDB, use_openai: bool = True):
    """
    ëŒ€í™”í˜• ê²€ìƒ‰ ëª¨ë“œ
    
    Args:
        speech_db: ë¡œë“œëœ ìŒì„± ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
        use_openai: OpenAI ì„ë² ë”© ì‚¬ìš© ì—¬ë¶€
    """
    print("\nğŸ¯ Interactive Speech Search Mode")
    if use_openai:
        print("ğŸ¤– Using OpenAI embeddings (dimension reduced to 768)")
    else:
        print("âš¡ Using fallback hash-based embeddings")
    
    print("Commands:")
    print("  - Type text query for semantic search")
    print("  - Type 'keywords: word1,word2' for keyword search")
    print("  - Type 'time: HH:MM:SS.mmm-HH:MM:SS.mmm' for time range search")
    print("  - Type 'video: video_id' to set video filter")
    print("  - Type 'sentiment: positive/negative/neutral' to set sentiment filter")
    print("  - Type 'importance: high/medium/low' to set importance filter")
    print("  - Type 'random' for random query")
    print("  - Type 'stats' for database statistics")
    print("  - Type 'videos' to list all videos")
    print("  - Type 'sentiments' for sentiment distribution")
    print("  - Type 'importance' for importance distribution")
    print("  - Type 'chunks: video_id' to list all chunks of a video")
    print("  - Type 'reset' to reset all filters")
    print("  - Type 'toggle' to switch embedding mode")
    print("  - Type 'quit' to exit")
    
    # í˜„ì¬ í•„í„° ì„¤ì •
    current_video_filter = None
    current_sentiment_filter = None
    current_importance_filter = None
    
    while True:
        try:
            # í˜„ì¬ í•„í„° ìƒíƒœ í‘œì‹œ
            filters = []
            if current_video_filter:
                filters.append(f"video={current_video_filter}")
            if current_sentiment_filter:
                filters.append(f"sentiment={current_sentiment_filter}")
            if current_importance_filter:
                filters.append(f"importance={current_importance_filter}")
            
            filter_str = f" [Filters: {', '.join(filters)}]" if filters else ""
            
            query = input(f"\nğŸ” Enter query (or command){filter_str}: ").strip()
            
            if query.lower() == 'quit':
                break
            elif query.lower() == 'toggle':
                use_openai = not use_openai
                mode = "OpenAI embeddings" if use_openai else "Hash-based embeddings"
                print(f"ğŸ”„ Switched to: {mode}")
                continue
            elif query.lower() == 'reset':
                current_video_filter = None
                current_sentiment_filter = None
                current_importance_filter = None
                print("ğŸ”„ All filters reset")
                continue
            elif query.lower() == 'stats':
                stats = speech_db.get_stats()
                print("\nğŸ“Š Database Statistics:")
                for key, value in stats.items():
                    print(f"   {key}: {value}")
                continue
            elif query.lower() == 'videos':
                print("\nğŸ¬ Videos in database:")
                for video_id in speech_db.video_metadata.keys():
                    meta = speech_db.video_metadata[video_id]
                    print(f"   - {video_id}: {meta['chunk_count']} chunks")
                continue
            elif query.lower() == 'sentiments':
                sentiments = speech_db.get_sentiment_distribution(current_video_filter)
                print(f"\nğŸ˜Š Sentiment Distribution{' for ' + current_video_filter if current_video_filter else ''}:")
                for sentiment, count in sentiments.items():
                    print(f"   {sentiment}: {count}")
                continue
            elif query.lower() == 'importance':
                importance = speech_db.get_importance_distribution(current_video_filter)
                print(f"\nâ­ Importance Distribution{' for ' + current_video_filter if current_video_filter else ''}:")
                for level, count in importance.items():
                    print(f"   {level}: {count}")
                continue
            elif query.startswith('video:'):
                video_id = query.split(':', 1)[1].strip()
                if video_id in speech_db.video_metadata:
                    current_video_filter = video_id
                    print(f"ğŸ¬ Video filter set to: {video_id}")
                else:
                    print(f"âŒ Video '{video_id}' not found in database")
                continue
            elif query.startswith('sentiment:'):
                sentiment = query.split(':', 1)[1].strip().lower()
                current_sentiment_filter = sentiment
                print(f"ğŸ˜Š Sentiment filter set to: {sentiment}")
                continue
            elif query.startswith('importance:'):
                importance = query.split(':', 1)[1].strip().lower()
                current_importance_filter = importance
                print(f"â­ Importance filter set to: {importance}")
                continue
            elif query.startswith('chunks:'):
                video_id = query.split(':', 1)[1].strip()
                chunks = speech_db.get_video_speech_chunks(video_id)
                if chunks:
                    print(f"\nğŸ™ï¸  Speech chunks for video {video_id}:")
                    print_search_results(chunks)
                else:
                    print(f"âŒ No chunks found for video '{video_id}'")
                continue
            elif query.startswith('keywords:'):
                keywords_str = query.split(':', 1)[1].strip()
                keywords = [kw.strip() for kw in keywords_str.split(',')]
                print(f"ğŸ”‘ Searching by keywords: {keywords}")
                
                # Top-k ê°œìˆ˜ ì…ë ¥
                k = 5
                
                # í‚¤ì›Œë“œ ê²€ìƒ‰ ìˆ˜í–‰
                results = speech_db.search_by_keywords(keywords, k=k, video_id=current_video_filter)
                
                if results:
                    print_search_results(results, f"Keywords: {', '.join(keywords)}")
                else:
                    print("âŒ No results found.")
                continue
            elif query.startswith('time:'):
                time_range = query.split(':', 1)[1].strip()
                try:
                    start_time, end_time = time_range.split('-')
                    start_time = start_time.strip()
                    end_time = end_time.strip()
                    print(f"â° Searching by time range: {start_time} - {end_time}")
                    
                    # ì‹œê°„ ë²”ìœ„ ê²€ìƒ‰ ìˆ˜í–‰
                    results = speech_db.search_by_time_range(start_time, end_time, video_id=current_video_filter)
                    
                    if results:
                        print_search_results(results, f"Time range: {start_time} - {end_time}")
                    else:
                        print("âŒ No results found.")
                except ValueError:
                    print("âŒ Invalid time format. Use: HH:MM:SS.mmm-HH:MM:SS.mmm")
                continue
            elif query.lower() == 'random':
                query_embedding = generate_random_query_embedding(speech_db.dimension)
                query_text = "Random Query"
            else:
                if use_openai:
                    print("ğŸ¤– Generating OpenAI embedding...")
                    query_embedding = generate_text_embedding_with_openai(query, speech_db.dimension)
                else:
                    query_embedding = generate_text_embedding_fallback(query, speech_db.dimension)
                query_text = query
            
            # Top-k ê°œìˆ˜ ì…ë ¥
            k = 5
            
            # ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
            results = speech_db.search_similar_speech(
                query_embedding, 
                k=k, 
                video_id=current_video_filter,
                sentiment_filter=current_sentiment_filter,
                importance_filter=current_importance_filter
            )
            
            if results:
                print_search_results(results, query_text)
            else:
                print("âŒ No results found.")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Goodbye!")
            break
        except Exception as e:
            print(f"âŒ Error: {e}")
            import traceback
            traceback.print_exc()


def main():
    parser = argparse.ArgumentParser(description="Speech Vector Database Search Tester")
    parser.add_argument("faiss_path", help="Path to .faiss file (without extension)")
    parser.add_argument("--query", "-q", type=str, help="Query text for search")
    parser.add_argument("--keywords", type=str, help="Comma-separated keywords for search")
    parser.add_argument("--time-range", type=str, help="Time range for search (HH:MM:SS.mmm-HH:MM:SS.mmm)")
    parser.add_argument("--video-id", type=str, help="Filter by specific video ID")
    parser.add_argument("--sentiment", type=str, choices=['positive', 'negative', 'neutral'], help="Filter by sentiment")
    parser.add_argument("--importance", type=str, choices=['high', 'medium', 'low'], help="Filter by importance")
    parser.add_argument("--k", "-k", type=int, default=5, help="Number of top results to return")
    parser.add_argument("--random", "-r", action="store_true", help="Use random query vector")
    parser.add_argument("--interactive", "-i", action="store_true", help="Interactive search mode")
    parser.add_argument("--dimension", "-d", type=int, default=768, help="Vector dimension (default: 768)")
    parser.add_argument("--no-openai", action="store_true", help="Use fallback embeddings instead of OpenAI")
    
    args = parser.parse_args()
    
    # OpenAI ì‚¬ìš© ì—¬ë¶€ ê²°ì •
    use_openai = not args.no_openai
    
    # .faiss í™•ì¥ì ì²˜ë¦¬
    faiss_path = args.faiss_path
    if not faiss_path.endswith('.faiss'):
        faiss_path += '.faiss'
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    index_path = faiss_path.replace('.faiss', '_index.faiss')
    metadata_path = faiss_path.replace('.faiss', '_metadata.pkl')
    
    if not os.path.exists(index_path):
        print(f"âŒ Index file not found: {index_path}")
        return
    
    if not os.path.exists(metadata_path):
        print(f"âŒ Metadata file not found: {metadata_path}")
        return
    
    print(f"ğŸ“‚ Loading speech vector database from: {faiss_path}")
    
    try:
        # ìŒì„± ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ
        speech_db = SpeechVectorDB.load(faiss_path, dimension=args.dimension)
        
        # í†µê³„ ì¶œë ¥
        stats = speech_db.get_stats()
        print(f"âœ… Database loaded successfully!")
        print(f"   ğŸ“Š Total vectors: {stats['total_vectors']}")
        print(f"   ğŸ¬ Total videos: {stats['total_videos']}")
        print(f"   ğŸ™ï¸  Total speech chunks: {stats['total_speech_chunks']}")
        print(f"   ğŸ“ Vector dimension: {stats['dimension']}")
        
        if use_openai:
            print(f"   ğŸ¤– Using OpenAI embeddings (dimension reduced to {args.dimension})")
        else:
            print(f"   âš¡ Using fallback embeddings")
        
        if stats['total_vectors'] == 0:
            print("âš ï¸  Database is empty!")
            return
        
        # ëŒ€í™”í˜• ëª¨ë“œ
        if args.interactive:
            interactive_search(speech_db, use_openai)
            return
        
        # ë‹¨ì¼ ì¿¼ë¦¬ ëª¨ë“œ
        if args.random:
            query_embedding = generate_random_query_embedding(args.dimension)
            query_text = "Random Query"
            results = speech_db.search_similar_speech(
                query_embedding, 
                k=args.k, 
                video_id=args.video_id,
                sentiment_filter=args.sentiment,
                importance_filter=args.importance
            )
        elif args.keywords:
            keywords = [kw.strip() for kw in args.keywords.split(',')]
            query_text = f"Keywords: {', '.join(keywords)}"
            results = speech_db.search_by_keywords(keywords, k=args.k, video_id=args.video_id)
        elif args.time_range:
            try:
                start_time, end_time = args.time_range.split('-')
                start_time = start_time.strip()
                end_time = end_time.strip()
                query_text = f"Time range: {start_time} - {end_time}"
                results = speech_db.search_by_time_range(start_time, end_time, video_id=args.video_id)
            except ValueError:
                print("âŒ Invalid time format. Use: HH:MM:SS.mmm-HH:MM:SS.mmm")
                return
        elif args.query:
            if use_openai:
                print("ğŸ¤– Generating OpenAI embedding...")
                query_embedding = generate_text_embedding_with_openai(args.query, args.dimension)
            else:
                query_embedding = generate_text_embedding_fallback(args.query, args.dimension)
            query_text = args.query
            results = speech_db.search_similar_speech(
                query_embedding, 
                k=args.k, 
                video_id=args.video_id,
                sentiment_filter=args.sentiment,
                importance_filter=args.importance
            )
        else:
            print("âŒ Please provide --query, --keywords, --time-range, --random, or --interactive option")
            return
        
        # ê²€ìƒ‰ ìˆ˜í–‰
        print(f"\nğŸ” Searching for top-{args.k} results...")
        
        if results:
            print_search_results(results, query_text)
        else:
            print("âŒ No results found.")
    
    except Exception as e:
        print(f"âŒ Error loading or searching database: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 